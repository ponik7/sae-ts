# Отчет по проекту SAE-TS

## 1. Введение
### Описание задачи
В этом проекте хотелось повторить статью SAE-TS и научиться "стирить" модели, направляя их в заранее заданную сторону.

### Цели проекта
1. Застирить модель gemma2-2b-it.
2. Попробовать метод без и с нормализацией на норму hidden вектора.

## 2. Методология
### 2.1 Архитектура модели
- Модель gemma2-2b-it со стандартной для этого семейства архитектурой.

### 2.2 Процесс стиринга
В качестве фичи взял id 12332, отвечающую за французский язык. Взял 20 разных альфа, сгенерировал равномерно с помощью np.linspace в промежутке от -300 до 300 (в целом на neuronpedia промежутки именно такие). Применил оба метода (с/без нормализации). Посчитал скор с помощью 4o-mini, для этого написал промпт: ллм с помощью какого-либо критерия (конкретно тут Fluency и Behavioral score) должна оценить соответствие ответа модели gemma2-2b-it этому критерию по 10-балльной шкале. Отрисовал и сохранил графики в assets.

### 2.3 Проблемы при стиринге
Долго мучился с forward hook, из-за того, что outputs - tuple, где второй элемент это hybrid_cache какое-то время не мог побороть проблему с размерностями, т.к. модель проходила forward hook пару раз, первый для kv_cache, второй forward. Позже засунул скейлинг внутрь определения хука и аккуратно вернул правильный результат.

Была проблема с пониманием скейлинга, сначала тяжело было вникнуть какой промежуток для alpha брать, позже в статье дочитал до нужного места и посмотрел на neuronpedia. alpha от авторов была равна 122, после того как применил, сразу получил ответ на французском от модели - успех.


## 3. Результаты

<img src="assets/behavioral_score_vs_alpha_method_1.png" alt="behavioral score" width="500"/>
На этом графике показан behavioral score первого метода, в качестве критерия использовался "French language use". В целом, ожидаемо высокий скор получается около alpha=122 (напомню, что это оригинальное значение из neuronpedia). Выше, кстати, скор остался таким же высоким, модель все так же продолжала генерировать текст на французском, что ожидаемо.

<img src="assets/fluency_score_vs_alpha_method_1.png" alt="behavioral score" width="500"/>
На данном графике показан fluency score первого метода. Эта метрика требовалась в задании, но на мой взгляд она не слишком хорошо интерпретируема, т.к. модель на разных альфа хорошо генерирует текст (и на английском и на французском), тут у нее проблем нет.

<img src="assets/behavioral_score_vs_alpha_method_2.png" alt="behavioral score" width="500"/>
behavioral score второго метода. Отличий от первого метода не особо много, кроме того, что тут мы смогли добиться максимального скора 10 (у первого метода максимум был на 9), что интересно. Видимо, нормализация все же играет свою роль, хоть я и не сказал бы, что конкретно здесь это значимо.

<img src="assets/fluency_score_vs_alpha_method_2.png" alt="behavioral score" width="500"/>
fluency score второго метода такой же неинтерпретируемый как и у первого.


## 5. Список литературы
1. [Improving Steering Vectors by Targeting Sparse Autoencoder Features](https://arxiv.org/pdf/2411.02193)